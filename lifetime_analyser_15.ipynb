{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "026332c2-5663-44f9-96c3-b03357d77dd2",
   "metadata": {},
   "source": [
    "# Sinton Lifetime Analyser\n",
    "\n",
    "This code opens a series of Sinton Lifetime Excel files, saves them into a panda dataframe, and displays a dash plot where the different files can be explored. \n",
    "\n",
    "You can then choose which of the files to analyse and plot separately.\n",
    "\n",
    "First we start by importing some useful libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "64bc328c-d46c-4f99-9933-7d044f6e2d19",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib\n",
    "import pandas as pd\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# the library below is not standard, and needs to be added to the same folder.\n",
    "import lifetime_functions_15 as tau_func\n",
    "# additionally make sure that the 'SiliconData.mat' file also exists in the same folder."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c68ef98-2eb1-4dfd-b790-80ec9f85dab0",
   "metadata": {},
   "source": [
    " ### Now let's check all .xlsm files in a folder, and get a list of the files we will analyse. It gives the chance of adding or deleting files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffee720d-8330-4539-9be5-e91092e939c1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# since the macro files from Sinton have some warnings, best to ignore them\n",
    "warnings.filterwarnings('ignore', category=UserWarning, module='openpyxl')\n",
    "\n",
    "# Create a dictionary to hold the dataframes\n",
    "excel_files = {}\n",
    "\n",
    "#select a folder (remember in python you need \\\\ for the folder path)\n",
    "\n",
    "# folder_path = 'C:\\\\Users\\\\user\\\\OneDrive - Nexus365\\\\data_examples'\n",
    "folder_path = '../data_examples/Yan_Dec24_EnAdvpaper/'\n",
    "\n",
    "print(folder_path)\n",
    "\n",
    "# Loop through all files in a directory selected by the user\n",
    "for file in os.listdir(folder_path):\n",
    "    # Check if the file is an Excel file\n",
    "    if file.endswith('.xlsm'):\n",
    "        # Create a dataframe from the Excel file\n",
    "        file_path = os.path.join(folder_path, file)\n",
    "        excel_files[file] = pd.read_excel(file_path)\n",
    "print(\"Loaded Excel files:\")\n",
    "for file_name in excel_files:\n",
    "    print(file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "562804ff-f35f-45b4-b8c4-6412ace129f1",
   "metadata": {},
   "source": [
    "### Plot all of the lifetimes into a single plot that allows exploring the data.\n",
    "If you get errors here it is likely some of the Excel Sinton files are corrupted or are using an older version of the software."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e320944-59fc-4c57-8d93-04159535d876",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_lib = {}# library of all the data_frames lodaded\n",
    "\n",
    "# Create a Plotly figure with subplots\n",
    "fig = make_subplots()\n",
    "fig.update_xaxes(type='log',exponentformat = 'power'); fig.update_yaxes(type='log')\n",
    "fig.update_xaxes(minor=dict(ticks=\"inside\", ticklen=6, showgrid=True))\n",
    "fig.update_xaxes(title_text=\"Delta N [cm^-3]\"); fig.update_yaxes(title_text=\"Tau Effective (s)\")\n",
    "\n",
    "for file_name in excel_files:\n",
    "    print(\"reading: \",file_name)\n",
    "    file_path = os.path.join(folder_path, file_name)\n",
    "    df1=pd.read_excel(file_path ,sheet_name='RawData')\n",
    "    df3=pd.read_excel(file_path, sheet_name='User',nrows=1,header=4)\n",
    "\n",
    "    #create a new dataframe that has all information of a single sample in it.\n",
    "    trunc_ix=3; #remove the first and last 3 values of the lifetime plot.\n",
    "    df = pd.DataFrame({df3.iloc[0,0]:#sample name\n",
    "        [df3.iloc[0,1],#thickness in cm\n",
    "        df3.iloc[0,2],#resisitivity in ohm.cm\n",
    "        df3.iloc[0,3],#Si type\n",
    "        df1['Minority Carrier Density'].iloc[trunc_ix:-trunc_ix],#iloc[4]: Delta_n\n",
    "        df1['Tau (sec)'].iloc[trunc_ix:-trunc_ix],#iloc[5]: Teff\n",
    "        df1['Implied Voc'].iloc[trunc_ix:-trunc_ix],#iloc[6]: iVoc\n",
    "        df1['Implied Suns'].iloc[trunc_ix:-trunc_ix]]})#iloc[7]: iSuns\n",
    "    \n",
    "    df_lib[file_name]=df\n",
    "    sample_name=df.columns[0]\n",
    "    delta_n=df.iloc[3,0]\n",
    "    tau_eff=df.iloc[4,0]\n",
    "    fig.add_trace(go.Scatter(x=delta_n, y=tau_eff, mode='markers', name=file_name))\n",
    "\n",
    "fig.update_layout(\n",
    "    margin=dict(l=150, r=350, t=20, b=20),\n",
    "    paper_bgcolor=\"white\",\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "813773dc-2e9d-4e5c-901f-013833ed3d92",
   "metadata": {},
   "source": [
    "## Decide which excel file you would like to analyse to get the Surface Recombination parameters\n",
    "To make sure it is all clear, here are all the main equations that define how these parameters are analysed. I've provided a word document with the main equations. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3005f75-f27d-488d-b2ec-2c19be2d52ed",
   "metadata": {},
   "source": [
    "Some useful advice for extracting J0:\n",
    " \n",
    "- Start by letting the software fit the tn, tp, and E_t values.\n",
    "- Check that the fit makes sense in the figure. Remember this code does not fit lifetime, it finds the SRH term that is most compatible with a carrier-independent J_0s average term, as per Kimmerle's method.\n",
    "- If you are doing many samples at the same time, and you cannot check all of them, start on the assumption that they all have the same bulk lifetime.\n",
    "- This means setting a strict value of the SRH bulk via tn, tp, and E_t.\n",
    "- Often you can find out how much defect mediated recombination sample have based on a sample with reasonable passivation (J0s<10 fA/Cm2)\n",
    "- Then use this to fit the best possible SRH, and analyse all samples with a single value of SRH bulk.\n",
    "- Conversely, if your processes aim to change the bulk, but you have a good confidence of the surface passivation, then set the value of J0s and allow the fitted to find the best recombination parameters it can find. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c2576d3-dc0c-42da-a133-40268beeb05e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Enter a fileID number from 0 to (max files - 1), and the app will analyse such file.\n",
    "file_ID=0\n",
    "files_in= list(df_lib.keys())\n",
    "print(f\"Analysing File ID number {file_ID}: {files_in[file_ID]}\")  # Output: Key at index 1: b\n",
    "\n",
    "# change the plot_options=0 if you do not want to plot the result of the analysis\n",
    "plot_option=1;\n",
    "\n",
    "# set any options for the fitting of SRH lifetime using the array below\n",
    "# srh_fit_options=np.array([0,0.01,0.56,0.8e-15]) # specify values of tn [s], tp [s], Et-Ev [eV], J0 [A/cm2] (leave as zero for fitting)\n",
    "srh_fit_options=np.array([0.0,0.0,0.56,0e-15]) # specify values of tn [s], tp [s], Et-Ev [eV], J0 [A/cm2] (leave as zero for fitting)\n",
    "\n",
    "try:\n",
    "    results_df=tau_func.extract_srv(df_lib[files_in[file_ID]],plot_option,srh_fit_options)\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"\\n \\n **** Error processing {files_in[file_ID]}: {e} ****\\n \\n \")\n",
    "\n",
    "# after finishing the fit, the algorithm will state if it finished by finding the smallest variation in the function (ftol) \n",
    "# aim for MSE's velu 1e-6  (the lower the better)\n",
    "# print(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f57b38b-48b0-43f4-8053-13ff348c9961",
   "metadata": {},
   "source": [
    "## if you would like to save the results into a csv file run the cell below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "746690b4-12f5-4ff7-9731-e0f54491d31a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tau_func.save_file(results_df,file_name.replace('.xlsm', '.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e39f0c38-a221-406a-b69b-cc0108583978",
   "metadata": {},
   "source": [
    "## If you would like to analyse all of the files inside of the folder, you can use the cell below.\n",
    "Execute carefully as it may take a long time to analyse very big folders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5acd008-8b9e-4238-9b32-f1e46d52774c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "delta_n_key=1e15 # you need to define at which Delta_N all resuls should be reported\n",
    "\n",
    "#then execute the below to do the analysis\n",
    "df_lib_results = {'variable':[['T_eff'],['S_eff1'],['S_eff2'],['S_eff3'],['J0avg'],['J0_Kimmerle2'],['iVoc'],['mse'],['SRH']]}# library of all the analysed results\n",
    "                  \n",
    "for file_name in df_lib:\n",
    "    try:\n",
    "        results_df=tau_func.extract_srv(df_lib[file_name],0,srh_fit_options)\n",
    "\n",
    "        # extracting all variables and defining by name\n",
    "        sample_name=results_df.columns[0]\n",
    "        \n",
    "        # copy paste the same organisation structure as in save_file() function\n",
    "        waf_thick=results_df.iloc[0,0]\n",
    "        delta_n=results_df.iloc[3,0]\n",
    "        tau_eff=results_df.iloc[4,0]\n",
    "        delta_n2=results_df.loc[7,sample_name]\n",
    "        t_int=results_df.loc[8,sample_name]\n",
    "        nieff=results_df.loc[9,sample_name]\n",
    "        ndop=results_df.loc[10,sample_name]\n",
    "        Joe_avg=results_df.loc[11,sample_name]\n",
    "        tau_SRH=results_df.loc[12,sample_name]\n",
    "        [[Seff_1],[Seff_2],[Seff_3]]=results_df.loc[13,sample_name]\n",
    "        [[Joe6],[Joe2],[Joe1]]=results_df.loc[14,sample_name]\n",
    "        iVoc=results_df.loc[15,sample_name]\n",
    "        tau_eff2=results_df.loc[16,sample_name]\n",
    "        SRH_parms=results_df.loc[17,sample_name]\n",
    "        mse=results_df.loc[18,sample_name]\n",
    "        SunsVoc=results_df.loc[19,sample_name]\n",
    "\n",
    "\n",
    "        df_lib_results[file_name]=[[np.interp(delta_n_key,delta_n2,tau_eff2)],\n",
    "                                   [np.interp(delta_n_key,delta_n2,Seff_1)],\n",
    "                                   [np.interp(delta_n_key,delta_n2,Seff_2)],\n",
    "                                   [np.interp(delta_n_key,delta_n2,Seff_3)],\n",
    "                                   [Joe_avg],\n",
    "                                   [np.interp(delta_n_key,delta_n2,Joe2)],\n",
    "                                   [np.interp(delta_n_key,delta_n2,iVoc)],[mse],[SRH_parms]\n",
    "                                ]\n",
    "    except Exception as e:\n",
    "        print(f\"\\n \\n Error processing {file_name}: {e}\\n \\n \")\n",
    "    continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2178b1d8-e6ca-47c7-9e36-f85ebf49686f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#and finally execute this to save all your analysed results to an excel file.\n",
    "\n",
    "\n",
    "df_results = pd.DataFrame.from_dict(df_lib_results)\n",
    "for col in df_results:\n",
    "    df_results[col] = df_results[col].astype(str).str.replace(\"[\",\"\").str.replace(\"]\",\"\")\n",
    "       \n",
    "df_results.to_excel(\"all_summary_results.xlsx\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a6601cf-f19c-4f22-b2a2-b1ac2403f5e8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
